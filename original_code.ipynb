{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70</span> (280.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70\u001b[0m (280.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70</span> (280.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70\u001b[0m (280.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - loss: 1630.4741 - mae: 30.4905\n",
      "Epoch 2/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - loss: 25.1715 - mae: 3.5871\n",
      "Epoch 3/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step - loss: 18.7474 - mae: 3.1711\n",
      "Epoch 4/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 17.9544 - mae: 3.2129\n",
      "Epoch 5/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 20.1556 - mae: 3.2102\n",
      "Epoch 6/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 16.9959 - mae: 3.0898\n",
      "Epoch 7/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 15.6335 - mae: 2.9683\n",
      "Epoch 8/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 15.9682 - mae: 3.0253\n",
      "Epoch 9/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 13.3870 - mae: 2.7587\n",
      "Epoch 10/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - loss: 14.4945 - mae: 2.8793\n",
      "Epoch 11/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 12.6980 - mae: 2.6981\n",
      "Epoch 12/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - loss: 14.3270 - mae: 2.8244\n",
      "Epoch 13/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 13.1548 - mae: 2.7134\n",
      "Epoch 14/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 17.0601 - mae: 2.9872\n",
      "Epoch 15/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279us/step - loss: 12.7492 - mae: 2.6993\n",
      "Epoch 16/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 10.8768 - mae: 2.4897\n",
      "Epoch 17/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - loss: 12.5074 - mae: 2.5717\n",
      "Epoch 18/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 11.2122 - mae: 2.4365\n",
      "Epoch 19/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 10.6632 - mae: 2.3838\n",
      "Epoch 20/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - loss: 11.6427 - mae: 2.3604\n",
      "Epoch 21/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - loss: 9.9883 - mae: 2.3384\n",
      "Epoch 22/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step - loss: 11.6872 - mae: 2.4398\n",
      "Epoch 23/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - loss: 10.9411 - mae: 2.3837\n",
      "Epoch 24/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 10.5746 - mae: 2.3314\n",
      "Epoch 25/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - loss: 9.9348 - mae: 2.3086\n",
      "Epoch 26/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 9.5957 - mae: 2.2322\n",
      "Epoch 27/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 11.7264 - mae: 2.4667\n",
      "Epoch 28/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 281us/step - loss: 12.3423 - mae: 2.4237\n",
      "Epoch 29/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 9.6323 - mae: 2.2617\n",
      "Epoch 30/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277us/step - loss: 10.9786 - mae: 2.4036\n",
      "Epoch 31/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 10.3803 - mae: 2.3323\n",
      "Epoch 32/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 10.6406 - mae: 2.3526\n",
      "Epoch 33/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - loss: 8.7199 - mae: 2.1950\n",
      "Epoch 34/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 9.6695 - mae: 2.2784\n",
      "Epoch 35/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - loss: 9.0037 - mae: 2.2105\n",
      "Epoch 36/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - loss: 10.0472 - mae: 2.3066\n",
      "Epoch 37/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276us/step - loss: 9.8375 - mae: 2.2890\n",
      "Epoch 38/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - loss: 9.3209 - mae: 2.2382\n",
      "Epoch 39/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - loss: 9.7102 - mae: 2.2681\n",
      "Epoch 40/40\n",
      "\u001b[1m2203/2203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - loss: 9.3818 - mae: 2.2379\n",
      "10.352896690368652\n",
      "2.464005947113037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.compose\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('life_expectency.csv')\n",
    "dataset = dataset.drop(['Country'],axis = 1)\n",
    "features = dataset.iloc[:,0:-1]\n",
    "labels = dataset.iloc[:,-1]\n",
    "\n",
    "features = pd.get_dummies(features) #one-hot encoding\n",
    "\n",
    "features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size=0.25,random_state=25)\n",
    "\n",
    "\n",
    "#extracting numerical data from dataset\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    "ct = sklearn.compose.ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "\n",
    "features_train_scaled = ct.fit_transform(features_train)\n",
    "features_test_scaled = ct.transform(features_test)\n",
    "\n",
    "features_train_scaled = np.asarray(features_train_scaled).astype(np.float32)\n",
    "labels_train = np.asarray(labels_train).astype(np.float32)    \n",
    "features_test_scaled = np.asarray(features_test_scaled).astype(np.float32)    \n",
    "labels_test = np.asarray(labels_test).astype(np.float32)\n",
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(\n",
    "  InputLayer(\n",
    "    input_shape = (features_train_scaled.shape[1],)\n",
    "  )\n",
    ")\n",
    "my_model.add(Dense(3,activation=\"relu\"))\n",
    "my_model.add(Dense(1))\n",
    "my_model.summary()\n",
    "opt = Adam(learning_rate = 0.01)\n",
    "my_model.compile(loss='mse',metrics=['mae'],optimizer=opt)\n",
    "\n",
    "#train\n",
    "my_model.fit(features_train_scaled,labels_train,epochs=40,batch_size=1,verbose=1)\n",
    "# my_model.fit(data, labels, epochs = 20, batch_size = 1, verbose = 1,  validation_split = 0.2)\n",
    "res_mse,res_mae = my_model.evaluate(features_test_scaled,labels_test,verbose=0)\n",
    "\n",
    "print(res_mse)\n",
    "print(res_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
